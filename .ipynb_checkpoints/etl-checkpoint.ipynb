{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.filterwarnings('ignore')\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'postgres'\n",
    "password = 'x'\n",
    "database = 'troll_tweet_project'\n",
    "#connect to local SQL db\n",
    "engine = create_engine(f'postgresql://{username}:{password}@localhost/{database}')\n",
    "\n",
    "#create variable to connect to postgress db\n",
    "connection = engine.connect()\n",
    "\n",
    "# #create variable for default declarative base in sql alchemy\n",
    "# Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(1, 10):\n",
    "    file_path = f'data//russian-troll-tweets/IRAhandle_tweets_{x}.csv'\n",
    "    print(file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df1 = df['publish_date'].str.split(' ', expand=True ) #split the date and time\n",
    "    df['published_date'] = df1[0] #get only the date, and create new column\n",
    "    df['published_date'] =  pd.to_datetime(df['published_date'], format='%m/%d/%Y') #convert to datetime object\n",
    "    df['published_date'] =  (df['published_date'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s') #convert to epoch\n",
    "    df = df.drop(columns=['publish_date', 'harvested_date', 'new_june_2018']) #drop columns we know we wont use\n",
    "    df.to_sql('tweets', con=connection, if_exists='append', index=False, method='multi', chunksize=5000 )\n",
    "#     send_to_postgres(df)\n",
    "    #todo delete df\n",
    "    df = None\n",
    "    df1 = None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in postgres run the following queries:\n",
    "# -- ALTER TABLE tweets ADD COLUMN internal_tweet_number  SERIAL PRIMARY KEY;\n",
    "# -- update tweets set account_type = 'Ebola' where account_type = 'Ebola ';\n",
    "# -- CREATE INDEX tweet_id_index ON tweets (internal_tweet_number);\n",
    "# -- create index date_index on tweets (published_date);\n",
    "# -- delete from tweets where content is null;\n",
    "\n",
    "\n",
    "#uncomment the above queries in pdadmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
